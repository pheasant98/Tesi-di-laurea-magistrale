% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex

%**************************************************************
\chapter{Discussione e comparazione dei risultati}
\label{cap:risFin}
%**************************************************************
\intro{In questo capitolo si discuteranno i risultati ottenuti dai modelli di Bradley-Terry e dai modelli di machine learning. Si concluderà con una comparazione tra i modelli di data mining e quelli di machine learning.
}
%**************************************************************
\section{Discussione risultati dei modelli Bradley-Terry}
Come illustrato nel Capitolo \ref{cap:risultatiDM} sono state applicate quattro versione del modello Bradley-Terry. Con la prima versione, ovvero il modello Bradley-Terry standard \autocite{bradley1952rank} (\hyperref[for:3.9]{4.9}) è stato possibile costruire una base da cui partire per ottenere risultati sempre più esplicativi e precisi. Infatti, con l'applicazione delle covariate nelle comparazioni ovvero con il modello (\ref{for:5.1}), è stato possibile approfondire in che modo le variabili esplicative influenzano l'esito di una partita. Successivamente per abbassare la complessità del modello e per aumentarne la flessibilità, nel modello (\ref{for:4.9}) è stato introdotto e applicato il metodo di regolarizzazione LASSO. Infine, per approfondire gli effetti delle singole variabili esplicative a seconda della squadra in esame è stato applicato il modello \ref{for:5.2} in cui viene tolto l'effetto dell'intercetta.\\
Dai risultati ottenuti e dalle analisi condotte è possibile concludere quanto segue. Nel campionato italiano, ai fini della vittoria o, in generale, dell'ottenimento di buoni risultati è rilevante per una squadra adottare un comportamento tattico, in particolare, dell'utilizzo della costruzione dal basso e giocare prevalentemente nella propria metà campo. 
È importante che la squadra adotti un comportamento meno propenso a controllare il pallone per lungo tempo perché sia il possesso della palla \texttt{Poss} e sia la distanza percorsa con la palla \texttt{TotDist} non sono significavi. Inoltre, la squadra deve essere più propensa a giocare maggiormente la palla nella propria area di difesa per evitare contropiedi perché sia le stime del numero di tocchi in area di rigore \texttt{ToDefPen}, sia il numero di tocchi nella trequarti difensiva \texttt{ToDef3rd} e sia il numero di tocchi a centrocampo \texttt{ToMid3rd} sono associati ad un aumento della probabilità di vittoria. Avere perciò una buona difesa è fondamentale. La fase offensiva non deve essere troppo lunga in termini di possesso della palla. Infatti, il numero di tocchi fatti nella trequarti offensiva \texttt{ToAtt3rd} porta ad avere una diminuzione delle probabilità di vittoria ma se si fanno i giusti passaggi per entrare nell'area di rigore avversaria mantenendo sempre un possesso palla breve si aumentano le probabilità di vittoria come visto nella stima del numero di tocchi in area di rigore avversaria \texttt{ToAttPen}. Dalle analisi emerge che uno sbilanciamento verso la fase offensiva porta una forte diminuzione alle probabilità di vittoria. Considerando i casi di Inter e Atalanta, la prima si dimostra essere una dalle squadre che più tira in generale (\texttt{Sh}) e in porta (\texttt{SoT}). Alti valori sono presenti anche per l'Atalanta. Entrambe però mantengono troppo il controllo del pallone nell'area avversaria. Infatti, per entrambe le squadre si riscontrano notevoli diminuzioni della probabilità di vittoria a causa della stima del parametro di \texttt{ToAtt3rd}. Peggio ancora per l'Atalanta, che ha un gioco particolarmente offensivo (vedi \textit{\cite{ataGioco}}), che le fa ottenere una diminuzione della probabilità della vittoria dalla stima del parametro \texttt{ToAttPen}. Questo perché il prolungato controllo del pallone la porta a esporsi e a subire contropiede. Si è parlato spesso di contropiedi nella nostra analisi. Quello che emerge sempre in tema di fase offensiva è che, il numero di tiri è relativamente basso, fatto dimostrato dal notevole aumento della probabilità di vittoria portato della stima del rapporto gol/tiri \texttt{G/Sh}. Di conseguenza le squadre attaccano poco e, quando lo fanno, cercano di massimizzare la loro fase offensiva. Infatti, le partite nel campionato italiano spesso finiscono con un massimo di due o tre gol segnati. Pertanto, l'efficacia di un azione offensiva che porta al gol e la carenza di azioni offensive portano \texttt{Sh}, \texttt{SoT} ma soprattutto \texttt{G/Sh} ad assumere un elevato contributo nel determinare la vittoria.\\
Concludendo la trattazione sulla fase offensiva, si illustra quale sia il miglior modo di attaccare che emerge dai modelli. Si sa che il contropiede è efficace, ma allo stesso tempo difficile da attuare per via del comportamento delle squadre a non sbilanciarsi. Una valida alternativa che emerge è il lancio lungo che parte dall'area compressa tra l'area di rigore della squadra fino a centrocampo ed arriva nell'area avversaria. Infatti, la stima del parametro del numero di passaggi lunghi tentati \texttt{LPAtt} è associata ad una crescita della probabilità di vittoria. L'utilizzo di passaggi filtrati \texttt{MPCmp\%} non è una buona tattica. Analogamente anche i cross \texttt{Crs} non danno benefici. Anzi, causano svantaggi, e ancora una volta ne rimangono penalizzate Inter e soprattutto Atalanta che con il suo gioco sfrutta molto le fasce (vedi \textit{\cite{ataGioco}}). In conclusione, è importante sottolineare che un atteggiamento troppo speculativo o difensivo da parte della squadra non porta alla vittoria. Questo è il caso del Venezia, classificatosi come ultimo, e che ha ottenuto benefici dalle covariate \texttt{ToDefPen} e \texttt{ToDef3rd} ma non dalle variabili esplicative offensive. Dall'analisi emerge che per ottenere la vittoria una squadra debba mantenere un comportamento tattico e giocare prevalentemente nella propria metà campo.\\
Infine, ogni modello ha prodotto delle predizioni dei risultati di alcune partite. Si sono confrontate le prestazioni dei quattro modelli durante la fase di test tra loro insieme alle predizioni fatte dai \emph{bookmakers}. Quello che si evince è che tutti i modelli Bradley-Terry hanno prestazioni migliori delle predizioni dei \emph{bookmakers}, segno che le informazioni vengo utilizzate correttamente. Purtroppo, dato che i modelli di \emph{data mining} mirano a interpretare le relazioni tra i dati e non a imparare caratteristiche molto complesse dei dati, non sono adatti alle predizioni. Infatti, si ottengono delle discrete prestazioni dal punto di vista dell'accuratezza, precisione, sensibilità e della specificità. Il modello Bradley-Terry che ha ottenuto le migliori prestazioni in fase di predizione è stato (\ref{for:4.9}).
\section{Discussione risultati dei modelli di machine learning}
Gli algoritmi di apprendimento automatico scelti sono stati utilizzati per predire l'esito di un insieme di partite, ovvero classificare le partite con una delle classi: vittoria della squadra in casa, pareggio o vittoria della squadra ospite.\\
Gli algoritmi utilizzati sono il K-Nearest-Neighbors (K-NN), la Support Vector Machine (SVM), il Decision Tree, la Random Forest e l'AdaBoost. L'algoritmo K-NN è stato scelto perché è semplice da implementare e rapido nell'esecuzione. L'algoritmo SVM è spesso impiegato grazie all'utilizzo del \emph{kernel trick} che permette all'algoritmo di adattarsi bene in vari contesti. Per questa ragione si è deciso di applicare la SVM. L'algoritmo Decision Tree oltre a essere semplice da implementazione e molto usato, è stato scelto anche per individuare quali sono le \emph{features} più decisive per la predizione. Infine, sono stati scelti gli algoritmi Random Forest e AdaBoost perché entrambi sono due tecniche di apprendimento \emph{ensemble} ma con filosofie differenti. Inoltre, il Random Forest permette di individuare quali \emph{features} danno maggior guadagno di informazioni.\\
Grazie alla metrica AUC è possibile confrontare le performance degli algoritmi utilizzati. Nella Figura \ref{fig:auc} vengono riportate le AUC che sono state misurate durante la fase di predizione di ogni algoritmo utilizzato.
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.30]{auc.png}
		\caption{Grafico a barre in cui viene riportata la Area Under the Curve (AUC) registrata durante la fase di predizione dei algoritmi K-Nearest-Neighbors (K-NN),  Support Vector Machine (SVM), Decision Tree, Random Forest e AdaBoost.  
		} 
		\label{fig:auc}
	\end{center}
\end{figure}
Dalle misurazioni ottenute si evince che l'AUC più alta è stata registrata nell'algoritmo SVM con un valore pari a 0.82. Infatti, la SVM ha una buona accuratezza perché è l'algoritmo che riesce a identificare con maggior precisione la classe pareggio, la quale è risultata molto ostica da identificare per gli algoritmi trattati. Con una AUC leggermente inferiore, l'algoritmo AdaBoost si classifica come secondo con un valore pari a 0.78. Analogamente alla SVM, l'AdaBoost si distingue dagli algoritmi con prestazioni inferiori grazie alle discrete prestazioni nell'identificazione della classe pareggio. L'algoritmo con la terza AUC più alta è stato il Random Forest con una AUC pari a 0.77 e con prestazioni simili all'algoritmo AdaBoost.
In quarta posizione si piazza l'algoritmo Decision Tree con una AUC pari a 0.75. Nonostante le buone prestazioni registrate nell'identificazione delle classi vittoria della squadra in casa e vittoria della squadra ospite, l'algoritmo Decision Tree paga una minor AUC a causa delle brutte prestazioni registrate nell'identificazione della classe pareggio. Infine, l'algoritmo con la più bassa AUC misurata è il K-NN con una AUC pari a 0.65. Infatti, l'algoritmo K-NN ha registrato delle pessime prestazioni nell'identificare le istanze di classe pareggio e delle discrete prestazioni nell'identificare le istanze delle altre due classi.\\
In conclusione, il problema presentato risulta essere troppo complesso per l'algoritmo K-NN: la strategia di classificare una nuova istanza con la classe di maggioranza dei k-vicini, seppur semplice, non è risultata efficace. Viceversa, la SVM, grazie all'utilizzo della funzione kernel, riesce a gestire la complessità dei dati ottenendo delle buone prestazioni in fase di predizione.
\section{Confronto}
Come riportato dai Capitoli \ref{cap:risultatiDM} e \ref{cap:RisML} le prestazioni migliori in fase di predizioni si ottengono con i metodi di \emph{machine learning}. Purtroppo, dato che i modelli di \emph{data mining} mirano a interpretare le relazioni tra i dati e non a imparare caratteristiche molto complesse dei dati, non sono adatti alle predizioni. Ciononostante, grazie all'interpretabilità di modelli è possibile individuare cosa influenza l'esito della partita e in che misura. Viceversa, i modelli di \emph{machine learning} in genere, si focalizzano su caratteristiche troppo complesse e difficili da interpretare. Grazie agli algoritmi Decision Tree e Random Forest è comunque possibile fare un confronto con i modelli Bradley-Terry, su quali variabili siano influenti per l'esito della partita.
Infatti, notiamo che le variabili legate ai tiri sono le più importanti per entrambi i modelli. Viene data importanza anche ai passaggi lunghi completati e alle variabili legate ai tocchi del pallone fatti. La maggior differenza che si ha tra le due tipologie di metodi la si ha nell'interpretazione dell'importanza del numero di parate. Per il modello Bradley-Terry la variabile influenza fortemente l'esito della partita, per i due modelli di \emph{machine learning} no.\\
Dal punto di vista dei tempi d'esecuzione si segnala una maggior velocità di esecuzione dei modelli Bradley-Terry rispetto ai modelli di \emph{machine learning}, in particolare l'algoritmo Random Forest impiega il maggior tempo d'esecuzione fra tutti gli algoritmi.

