% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex
%**************************************************************
\chapter{Discussione e comparazione dei risultati}
\label{cap:precls}
%**************************************************************
\intro{In questo capitolo si discuteranno i risultati ottenuti dai modelli di Bradley-Terry e dai modelli di machine learning. Si concluderà con una comparazione tra i modelli di data mining e quelli di machine learning.
}
%**************************************************************
\section{Discussione risultati dei modelli Bradley-Terry}
Come illustrato nel Capitolo \ref{cap:risultatiDM} sono state applicate quattro versione del modello Bradley-Terry. Con la prima versione, ovvero il modello Bradley-Terry standard \autocite{bradley1952rank} (\hyperref[for:3.9]{4.9}) è stato possibile stimare l'abilità di ogni singola squadra e l'effetto di giocare in casa, costruendo così, una base da cui partire per ottenere risultati sempre più esplicativi e precisi. Infatti, con l'introduzione di 26 covariate nelle comparazioni ovvero, con il modello (\ref{for:5.1}), è stato possibile approfondire in che modo le variabili esplicative influenzano l'esito di una partita. Successivamente per abbassare la complessità del modello e per analizzare come si comporta ogni covariata per ogni squadra, nel modello (\ref{for:4.9}) è stato introdotto e applicato il metodo di regolarizzazione LASSO. Per approfondire gli effetti delle singole variabili esplicative a seconda della squadra in esame è stato applicato il modello \ref{for:5.2} in cui viene tolto l'effetto dell'intercetta. Si sottolinea inoltre, come spiegato nel Capitolo \ref{cap:extraDM}, per utilizzare le variabili esplicative gol fatti \texttt{GF} e gol subiti \texttt{GA} è stato riapplicato il modello (\hyperref[for:3.9]{4.9}) ma con una variabile risposta \emph{Y} con cinque categorie invece che tre. Tale modello a livello di stime ha prodotto risultati simili al modello (\hyperref[for:3.9]{4.9}) con \emph{Y = 3}, con solo piccole differenze, permettendo così di raffinare l'analisi.\\
Dai risultati ottenuti e dalle analisi condotte è possibile concludere quanto segue. Nel campionato italiano, ai fini della vittoria o, in generale, dell'ottenimento di buoni risultati è rilevante per una squadra adottare un comportamento tattico, in particolare, dell'utilizzo della costruzione dal basso e giocare prevalentemente nella propria metà campo. 
È importante che la squadra adotti un comportamento meno propenso a controllare il pallone per lungo tempo perché sia il possesso della palla \texttt{Poss} e sia la distanza percorsa con la palla \texttt{TotDist} non sono significavi. Inoltre, la squadra deve essere più propensa a giocare maggiormente la palla nella propria area di difesa per evitare contropiedi perché sia le stime del numero di tocchi in area di rigore \texttt{ToDefPen}, sia il numero di tocchi nella trequarti difensiva \texttt{ToDef3rd} e sia il numero di tocchi a centrocampo \texttt{ToMid3rd} sono associati ad un aumento della probabilità di vittoria. Avere perciò una buona difesa è fondamentale. La fase offensiva non deve essere troppo lunga in termini di possesso della palla. Infatti, il numero di tocchi fatti nella trequarti offensiva \texttt{ToAtt3rd} porta ad avere una diminuzione delle probabilità di vittoria ma se si fanno i giusti passaggi per entrare nell'area di rigore avversaria mantenendo sempre un possesso palla breve si aumentano le probabilità di vittoria. Considerando i casi di Inter e Atalanta, %vedi grafico
la prima si dimostra essere una dalle squadre che più tira in generale (\texttt{Sh}) e in porta (\texttt{SoT}). Alti valori sono presenti anche per l'Atalanta. Entrambe però mantengono troppo il controllo del pallone nell'area avversaria. Infatti, per entrambe le squadre si riscontrano notevoli diminuzioni della probabilità di vittoria a causa della stima del parametro di \texttt{ToAtt3rd}. Peggio ancora per l'Atalanta, che ha un gioco particolarmente offensivo (vedi \textit{\cite{ataGioco}}), che le fa ottenere una diminuzione della probabilità della vittoria dalla stima del parametro \texttt{ToAttPen}, diversamente dalle altre squadre dove la stima è leggermente positiva. Questo perché il prolungato controllo del pallone la porta a esporsi e a subire il contropiede. Si è parlato spesso di contropiedi nella nostra analisi. Quello che emerge sempre in tema di fase offensiva è che, il numero di tiri è relativamente basso, fatto dimostrato dal notevole aumento della probabilità di vittoria portato della stima del rapporto gol/tiri \texttt{G/Sh}. Di conseguenza le squadre attaccano poco e, quando lo fanno, cercano di massimizzare la loro fase offensiva. Infatti, le partite nel campionato italiano spesso finiscono con un massimo di due o tre gol segnati. Pertanto, l'efficacia di un azione offensiva che porta al gol e la carenza di azioni offensive portano \texttt{Sh}, \texttt{SoT} ma soprattutto \texttt{G/Sh} ad assumere un elevato contributo nel determinare la vittoria.\\
Concludendo la trattazione sulla fase offensiva, si illustra quale sia il miglior modo di attaccare che emerge dai modelli. Si sa che il contropiede è efficace, ma allo stesso tempo difficile da attuare per via del comportamento delle squadre a non sbilanciarsi. Una valida alternativa che emerge è il lancio lungo che parte dall'area compressa tra l'area di rigore della squadra fino a centrocampo ed arriva nell'area avversaria. Infatti, la stima del parametro del numero di passaggi lunghi tentati \texttt{LPAtt} è associata ad una crescita della probabilità di vittoria. L'utilizzo di passaggi filtrati \texttt{MPCmp\%} non è una buona tattica infatti, essi sono associati a una diminuzione della probabilità di vittoria per tutte le squadre. Analogamente anche i cross \texttt{Crs} sono associati a diminuzione della probabilità di vittoria per tutte le squadre. Nello specifico vengono leggermente più penalizzate Roma, Milan, Napoli ma ancora una volta vengono particolarmente penalizzate Inter ma soprattutto l'Atalanta che con il suo gioco sfrutta molto le fasce (vedi \textit{\cite{ataGioco}}). Inoltre, il fuorigioco risulta essere associato a una diminuzione della probabilità per le squadre con l'abilità maggiore in particolare Milan, Napoli ma soprattutto Inter e Juventus. In conclusione, è importante sottolineare che un atteggiamento troppo speculativo o difensivo da parte della squadra non porta alla vittoria. Questo è il caso del Venezia, classificatosi come ultimo, e che ha ottenuto benefici dalle covariate \texttt{ToDefPen} e \texttt{ToDef3rd} ma non dalle variabili esplicative offensive. Perciò, dall'analisi emerge che per ottenere la vittoria una squadra debba mantenere un comportamento tattico e giocare prevalentemente nella propria metà campo.\\
Infine, ogni modello ha prodotto delle predizioni dei risultati di alcune partite. Si sono confrontate le prestazioni dei cinque modelli durante la fase di test tra loro insieme alle predizioni fatte dai \emph{bookmakers}. Quello che si evince è che tutti i modelli Bradley-Terry hanno prestazioni migliori delle predizioni dei \emph{bookmakers}, segno che le informazioni vengo utilizzate correttamente. Purtroppo, dato che i modelli di \emph{data mining} mirano a interpretare le relazioni tra i dati e non a imparare caratteristiche molto complesse dei dati, non sono adatti alle predizioni. Infatti, si ottengono delle discrete prestazioni dal punto di vista dell'accuratezza, precisione, sensibilità e della specificità. Il modello Bradley-Terry che ha ottenuto le migliori prestazioni in fase di predizione è stato (\ref{for:4.9}) ma con la variabile risposta \emph{Y} a cinque categorie. Infatti, con questa modifica si va a migliorare le prestazioni del modello (\ref{for:4.9}) che già risultava essere il più accurato con \emph{Y = 3}.
\section{Discussione risultati dei modelli di machine learning}
Gli algoritmi di apprendimento automatico scelti sono stati utilizzati per predire l'esito di un insieme di partite, ovvero classificare le partite con una delle classi: vittoria della squadra in casa, pareggio o vittoria della squadra ospite.\\
Gli algoritmi utilizzati sono il K-Nearest-Neighbors (K-NN), la Support Vector Machine (SVM), il Decision Tree, la Random Forest e l'AdaBoost. L'algoritmo K-NN è stato scelto perché è semplice da implementare e rapido nell'esecuzione. L'algoritmo SVM è spesso impiegato grazie all'utilizzo del \emph{kernel trick} che permette all'algoritmo di adattarsi bene in vari contesti. Per questa ragione si è deciso di applicare la SVM. L'algoritmo Decision Tree oltre a essere semplice da implementazione e molto usato, è stato scelto anche per individuare quali sono le \emph{features} più decisive per la predizione. Infine, sono stati scelti gli algoritmi Random Forest e AdaBoost perché entrambi sono due tecniche di apprendimento \emph{ensemble} ma con filosofie differenti. Inoltre, il Random Forest permette di individuare quali \emph{features} danno maggior guadagno di informazioni.\\
Grazie alla metrica AUC è possibile confrontare le performance degli algoritmi utilizzati. Nella Figura \ref{fig:auc} vengono riportate le AUC che sono state misurate durante la fase di predizione di ogni algoritmo utilizzato.
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.30]{auc.png}
		\caption{Grafico a barre in cui viene riportata la Area Under the Curve (AUC) registrata durante la fase di predizione dei algoritmi K-Nearest-Neighbors (K-NN),  Support Vector Machine (SVM), Decision Tree, Random Forest e AdaBoost.  
		} 
		\label{fig:auc}
	\end{center}
\end{figure}
Dalle misurazioni ottenute si evince che l'AUC più alta è stata registrata nell'algoritmo SVM con un valore pari a 0.82. Infatti, la SVM ha una buona accuratezza perché è l'algoritmo che riesce a identificare con maggior precisione la classe pareggio, la quale è risultata molto ostica da identificare per gli algoritmi trattati. Con una AUC leggermente inferiore, l'algoritmo AdaBoost si classifica come secondo con un valore pari a 0.78. Analogamente alla SVM, l'AdaBoost si distingue dagli algoritmi con prestazioni inferiori grazie alle discrete prestazioni nell'identificazione della classe pareggio. L'algoritmo con la terza AUC più alta è stato il Random Forest con una AUC pari a 0.77 e con prestazioni simili all'algoritmo AdaBoost.
In quarta posizione si piazza l'algoritmo Decision Tree con una AUC pari a 0.75. Nonostante le buone prestazioni registrate nell'identificazione delle classi vittoria della squadra in casa e vittoria della squadra ospite, l'algoritmo Decision Tree paga una minor AUC a causa delle brutte prestazioni registrate nell'identificazione della classe pareggio. Infine, l'algoritmo con la più bassa AUC misurata è il K-NN con una AUC pari a 0.65. Infatti, l'algoritmo K-NN ha registrato delle pessime prestazioni nell'identificare le istanze di classe pareggio e delle discrete prestazioni nell'identificare le istanze delle altre due classi.\\
In conclusione, il problema presentato risulta essere troppo complesso per l'algoritmo K-NN: la strategia di classificare una nuova istanza con la classe di maggioranza dei k-vicini, seppur semplice, non è risultata efficace. Viceversa, la SVM, grazie all'utilizzo della funzione kernel, riesce a gestire la complessità dei dati ottenendo delle buone prestazioni in fase di predizione.
\section{Confronto}
Come riportato dai Capitoli \ref{cap:risultatiDM}, \ref{cap:RisML} e  \ref{cap:extraDM} le prestazioni migliori in fase di predizioni si ottengono con i metodi di \emph{machine learning}. Purtroppo, dato che i modelli di \emph{data mining} mirano a interpretare le relazioni tra i dati e non a imparare caratteristiche molto complesse dei dati, non sono adatti alle predizioni. Ciononostante, grazie all'interpretabilità di modelli è possibile individuare cosa influenza l'esito della partita e in che misura. Viceversa, i modelli di \emph{machine learning} in genere, si focalizzano su caratteristiche troppo complesse e difficili da interpretare. Grazie agli algoritmi Decision Tree e Random Forest è comunque possibile fare un confronto con i modelli Bradley-Terry riguardo a quali variabili siano influenti per l'esito della partita.
Infatti, notiamo che le variabili legate ai tiri sono le più importanti per entrambi i modelli. Nei due modelli di \emph{machine learning} viene data molta importanza sia ai passaggi lunghi tentati, come per i modelli BT, ma anche alla percentuale di passaggi lunghi completati in contrasto con i modelli BT dove a tale variabile era assegnato una stima nulla a quasi tutte le squadre. 
Sia i modelli BT e sia i modelli Decision Tree e Random Forest, la \emph{features} della percentuale dei passaggi medi completati ricopre un ruolo importante nell'esito della partita, tuttavia, dai modelli BT sappiamo che essa incide negativamente sulla probabilità di vittoria.
Nonostante tante similitudini tra i risultati due tipologie di metodi, ci sono alcune differenze. Si hanno differenze di interpretazioni sull'importanza del numero di parate. Per il modello Bradley-Terry la variabile influenza fortemente l'esito della partita, per i due modelli di \emph{machine learning} no. Viceversa per quanto riguarda la percentuale di passaggi completati, per i due modelli di \emph{machine learning} è molto importante mentre per i modelli BT non influisce nell'esito di una partita. Analogamente anche per la distanza percorsa con la palla viene assegnata un rilevante guadagno di informazione, mentre nei modelli BT essa è irrilevante. Tuttavia, viene ribadita la poca importanza per entrambi i metodi riguardo al possesso della palla e delle variabili riguardanti al numero di contrasti vinti e il numero di intercetti. Anche i numeri di falli subiti e fatti non hanno una grande importanza per entrambi i metodi. Inoltre, per entrambi i metodi il numero di falli fatti è leggermente più rilevante rispetto al numero di falli subiti.\\
Dal punto di vista dei tempi d'esecuzione si segnala una maggior velocità di esecuzione dei modelli Bradley-Terry rispetto ai modelli di \emph{machine learning}, in particolare l'algoritmo Random Forest impiega il maggior tempo d'esecuzione fra tutti gli algoritmi.


